{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SRbOu4OCJZub"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c7b94e048744b5090260168d13ae7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5ea323ad2f64739897e78790925440a",
              "IPY_MODEL_05125306a511436c8a071f234eb4849a",
              "IPY_MODEL_570cae3f6d9649c784cfd68f43b6f716"
            ],
            "layout": "IPY_MODEL_beca089a471140f9be2d9421f898b256"
          }
        },
        "b5ea323ad2f64739897e78790925440a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4546c7a8190f4f66ab2b19a85ce63489",
            "placeholder": "​",
            "style": "IPY_MODEL_91d2d2164f1149f88938d40296aa7c93",
            "value": "Loss: 19.0832:  99%"
          }
        },
        "05125306a511436c8a071f234eb4849a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d1d8fc6cfe4a65bbabc2724aa88f08",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76022c6604884767976801d9face479f",
            "value": 4943
          }
        },
        "570cae3f6d9649c784cfd68f43b6f716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_435052a0872647158fb3afe91a713241",
            "placeholder": "​",
            "style": "IPY_MODEL_ef57d11d72e049aaac262547c3e5680b",
            "value": " 4943/5000 [1:16:17&lt;00:53,  1.07it/s]"
          }
        },
        "beca089a471140f9be2d9421f898b256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4546c7a8190f4f66ab2b19a85ce63489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d2d2164f1149f88938d40296aa7c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2d1d8fc6cfe4a65bbabc2724aa88f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76022c6604884767976801d9face479f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "435052a0872647158fb3afe91a713241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef57d11d72e049aaac262547c3e5680b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sudoku data handlers"
      ],
      "metadata": {
        "id": "WUSYgEdI9lJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "API surface: creates objects\n",
        "train_loader, test_loader, and the function check_sudoku(tensor)"
      ],
      "metadata": {
        "id": "MOFfjX6LJAHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "YB1yZ8CwJACA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q polars torch torchvision"
      ],
      "metadata": {
        "id": "7CUzgqwn-Mbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pdb on"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMX9EgLqFDr8",
        "outputId": "798c73f6-be1a-4256-9da9-7b97a3b033d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "ncnGkNXs-WZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv('/content/data/sudoku-small.csv', infer_schema_length=0)"
      ],
      "metadata": {
        "id": "OBGYgsZ8BkF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[3]['puzzle'].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ED7dcbNxDEJG",
        "outputId": "42b4daf4-c028-4a7e-a12d-47b0b44ce13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'008317000004205109000040070327160904901450000045700800030001060872604000416070080'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "008317000 \\\\\n",
        "004205109 \\\\\n",
        "000040070 \\\\\n",
        "327160904 \\\\\n",
        "901450000 \\\\\n",
        "045700800 \\\\\n",
        "030001060 \\\\\n",
        "872604000 \\\\\n",
        "416070080"
      ],
      "metadata": {
        "id": "mljxFiqglabd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([int(digit) for digit in df[3]['puzzle'].item()]).reshape(9,9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVhyCBAwCkt_",
        "outputId": "69567237-df0e-4685-b5ac-b9e584d7df7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 8, 3, 1, 7, 0, 0, 0],\n",
              "        [0, 0, 4, 2, 0, 5, 1, 0, 9],\n",
              "        [0, 0, 0, 0, 4, 0, 0, 7, 0],\n",
              "        [3, 2, 7, 1, 6, 0, 9, 0, 4],\n",
              "        [9, 0, 1, 4, 5, 0, 0, 0, 0],\n",
              "        [0, 4, 5, 7, 0, 0, 8, 0, 0],\n",
              "        [0, 3, 0, 0, 0, 1, 0, 6, 0],\n",
              "        [8, 7, 2, 6, 0, 4, 0, 0, 0],\n",
              "        [4, 1, 6, 0, 7, 0, 0, 8, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "204yf39a9jjA"
      },
      "outputs": [],
      "source": [
        "class SudokuDataset(Dataset):\n",
        "  def __init__(self, path=None, ds=None):\n",
        "    if not ds:\n",
        "      if not path:\n",
        "        raise Exception(\"where dataset parameters????\")\n",
        "      else:\n",
        "        self.ds = pl.read_csv(path, infer_schema_length=0)\n",
        "    else:\n",
        "      self.ds = ds\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ds)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.ds[idx]\n",
        "\n",
        "    puzzle = torch.tensor([int(digit) for digit in row['puzzle'].item()]).reshape(9,9)\n",
        "    # solution = torch.tensor([int(digit) for digit in row['solution'].item()]).reshape(9,9)\n",
        "\n",
        "    return F.one_hot(puzzle, 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SudokuDataset(path='/content/data/sudoku-small.csv')\n",
        "len_ds = len(dataset)\n",
        "\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, (int(0.8*len_ds), len_ds-int(0.8*len_ds)))\n"
      ],
      "metadata": {
        "id": "qgk2FDN5EMP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "train_loader, test_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size), DataLoader(train_set, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "JKt4IVSJEwkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(test_loader))[0].argmax(dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMFGhd5OE9qr",
        "outputId": "97570d3c-f282-4d0b-a257-65c711c1bf2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6, 0, 0, 0, 1, 7, 4, 0, 0],\n",
              "        [4, 0, 1, 0, 0, 3, 0, 0, 8],\n",
              "        [0, 5, 9, 8, 0, 0, 7, 2, 1],\n",
              "        [1, 2, 0, 0, 0, 0, 0, 5, 0],\n",
              "        [0, 0, 0, 0, 4, 0, 8, 0, 0],\n",
              "        [0, 0, 8, 0, 2, 0, 1, 0, 0],\n",
              "        [0, 0, 4, 5, 3, 0, 0, 0, 7],\n",
              "        [7, 0, 0, 0, 9, 0, 0, 8, 6],\n",
              "        [2, 6, 3, 1, 7, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_row_valid(board, row, num):\n",
        "    return num not in board[row]\n",
        "\n",
        "def is_col_valid(board, col, num):\n",
        "    return num not in board[:, col]\n",
        "\n",
        "def is_subgrid_valid(board, x, y, num):\n",
        "    subgrid_size = 3\n",
        "    startRow, startCol = subgrid_size * (x // subgrid_size), subgrid_size * (y // subgrid_size)\n",
        "    return num not in board[startRow:startRow + subgrid_size, startCol:startCol + subgrid_size]\n",
        "\n",
        "\n",
        "def has_legal_moves(board): # avoid cycling through all moves for speed - Danny\n",
        "    n = 9\n",
        "    empty_cells = np.argwhere(board == 0)\n",
        "    for x, y in empty_cells:\n",
        "        for num in range(1, n + 1):\n",
        "            if is_move_legal(board, x, y, num):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def is_move_legal(board, x, y, num):\n",
        "  n = 9\n",
        "  return is_row_valid(board, x, num) and \\\n",
        "            is_col_valid(board, y, num) and \\\n",
        "            is_subgrid_valid(board, x, y, num) and \\\n",
        "            0 < num <= n\n",
        "\n",
        "\n",
        "\n",
        "def get_legal_moves(board):\n",
        "      moves = []\n",
        "      n = 9\n",
        "      empty_cells = torch.chunk(np.argwhere(board == 0), 2)\n",
        "      ec0 = empty_cells[0].reshape(-1)\n",
        "      ec1 = empty_cells[1].reshape(-1)\n",
        "\n",
        "      for x, y in zip(ec0, ec1):\n",
        "          for num in range(1, n + 1):\n",
        "              if is_move_legal(board, x, y, num):\n",
        "                  moves.append((x, y, num))\n",
        "      return moves\n",
        "\n",
        "def get_valid_moves(board):\n",
        "    # Return a binary vector where each entry indicates if placing a number (1-9) in a cell (row, col) is valid\n",
        "    n = 9\n",
        "    # 3D\n",
        "    valid_moves = np.zeros((n, n, n+1))\n",
        "    moves = get_legal_moves(board) # list of (x, y, num) tuples\n",
        "    for x, y, num in moves:\n",
        "        valid_moves[x, y, num] = 1\n",
        "    return valid_moves\n"
      ],
      "metadata": {
        "id": "a80Mi3ghcgC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_row_valid_torch(board, num):\n",
        "    return ~torch.any(board == num, dim=1)\n",
        "\n",
        "def is_col_valid_torch(board, num):\n",
        "    return ~torch.any(board == num, dim=0)\n",
        "\n",
        "def is_subgrid_valid_torch(board, num):\n",
        "    subgrid_size = 3\n",
        "    n = 9\n",
        "    subgrids = board.view(n // subgrid_size, subgrid_size, -1, subgrid_size).transpose(1, 2)\n",
        "    exists_in_subgrids = torch.any(subgrids == num, dim=3).any(dim=2)\n",
        "    return ~exists_in_subgrids\n",
        "\n",
        "def is_move_legal_torch(board, num):\n",
        "    n = 9\n",
        "    row_valid = is_row_valid_torch(board, num)\n",
        "    col_valid = is_col_valid_torch(board, num)\n",
        "    subgrid_valid = is_subgrid_valid_torch(board, num)\n",
        "    return row_valid & col_valid & subgrid_valid\n",
        "\n",
        "def has_legal_moves_torch(board):\n",
        "    n = 9\n",
        "    for num in range(1, n + 1):\n",
        "        if torch.any(is_move_legal_torch(board, torch.tensor(num))):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def get_valid_moves_torch(board):\n",
        "    n = 9\n",
        "    valid_moves = torch.zeros((n, n, n + 1), dtype=torch.bool)\n",
        "    for num in range(1, n + 1):\n",
        "        legal_move_mask = is_move_legal_torch(board, torch.tensor(num))\n",
        "        valid_moves[:, :, num] = legal_move_mask\n",
        "    return valid_moves"
      ],
      "metadata": {
        "id": "T8-6-m17OAxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = next(iter(test_loader))[0]"
      ],
      "metadata": {
        "id": "4Cr9uljMkMRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "has_legal_moves_torch(x_test)"
      ],
      "metadata": {
        "id": "_7QMsuyMkRNy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe4201f0-b8dc-400a-f00b-cdd76b48f13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-165b195e845b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhas_legal_moves_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-237b30701a04>\u001b[0m in \u001b[0;36mhas_legal_moves_torch\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_move_legal_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-237b30701a04>\u001b[0m in \u001b[0;36mis_move_legal_torch\u001b[0;34m(board, num)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcol_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_col_valid_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msubgrid_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_subgrid_valid_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrow_valid\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mcol_valid\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0msubgrid_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhas_legal_moves_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (30) at non-singleton dimension 1"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[0;32m<ipython-input-23-237b30701a04>\u001b[0m(19)\u001b[0;36mis_move_legal_torch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     17 \u001b[0;31m    \u001b[0mcol_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_col_valid_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    \u001b[0msubgrid_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_subgrid_valid_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mrow_valid\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mcol_valid\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0msubgrid_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     20 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     21 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mhas_legal_moves_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> w\n",
            "  \u001b[0;32m<ipython-input-24-165b195e845b>\u001b[0m(1)\u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mhas_legal_moves_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "  \u001b[0;32m<ipython-input-23-237b30701a04>\u001b[0m(24)\u001b[0;36mhas_legal_moves_torch\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m     22 \u001b[0m    \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     23 \u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 24 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_move_legal_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m     25 \u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     26 \u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "> \u001b[0;32m<ipython-input-23-237b30701a04>\u001b[0m(19)\u001b[0;36mis_move_legal_torch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     17 \u001b[0;31m    \u001b[0mcol_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_col_valid_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    \u001b[0msubgrid_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_subgrid_valid_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mrow_valid\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mcol_valid\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0msubgrid_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     20 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     21 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mhas_legal_moves_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/debugger.py\", line 1075, in cmdloop\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--KeyboardInterrupt--\n",
            "\n",
            "KeyboardInterrupt: Interrupted by user\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model section"
      ],
      "metadata": {
        "id": "wZ0ZWGo2JXge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Idea\n",
        "\n",
        "its hard to predict the correct moves -- what if we let the model learn it implicitly :)"
      ],
      "metadata": {
        "id": "RNhY4WBBIV7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "jHUvb_DNlc3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = next(iter(test_loader))[0].argmax(dim=-1).numpy()\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkPV6G3EcVAy",
        "outputId": "02d1c408-7421-4bbc-9060-7e0a832a6a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_valid_moves(x)"
      ],
      "metadata": {
        "id": "1_Y3z57meVDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_reward(x: torch.TensorType):\n",
        "  num_solved = torch.count_nonzero(x.argmax(dim=-1)).item()\n",
        "  if num_solved == 81:\n",
        "    return 3\n",
        "  else:\n",
        "    return 1./num_solved"
      ],
      "metadata": {
        "id": "DKvl6nLS1Sht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StateFlow(nn.Module):\n",
        "  def __init__(self, num_hidden=512):\n",
        "    super().__init__()\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(810, num_hidden),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(num_hidden, 729*2)\n",
        "    ) # predict 810 states, mask out the ones we can't take (ie already filled or would conflict) -> sike we just let the model figure out the rest lmao\n",
        "\n",
        "    self.logZ = nn.Parameter(torch.ones(1))\n",
        "\n",
        "  def forward(self, x, init_board):\n",
        "    b = x.size(0)\n",
        "\n",
        "    valid_moves = torch.stack([torch.tensor(get_valid_moves(state)) for state in x.argmax(dim=-1)])\n",
        "\n",
        "    logits = self.mlp(x.float().view(x.size(0),-1))\n",
        "\n",
        "    # breakpoint()\n",
        "    pf = logits[:, :729].masked_fill((1-valid_moves[:, :, :, 1:]).bool().reshape(b, -1), -1e10)\n",
        "    # breakpoint()\n",
        "    pb = logits[:, 729:] * (1-init_board[:, :, :, 1:].reshape(b, -1)) * x[:, :, :, 1:].reshape(b, -1) * -10\n",
        "    return pf, pb"
      ],
      "metadata": {
        "id": "JjpxtlzFf-rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = StateFlow()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "num_epochs = 50000\n",
        "\n",
        "\n",
        "losses = []\n",
        "logZs = []\n",
        "\n",
        "generated_boards = []\n",
        "minibatch_loss = 0\n",
        "update_freq = 2\n",
        "\n",
        "pbar = tqdm(range(5000))\n",
        "for episode in pbar:\n",
        "  board = next(iter(train_loader)).float()\n",
        "  initial_board = board.clone().detach()\n",
        "\n",
        "  pf, pb = model(board, initial_board)\n",
        "\n",
        "  total_pf = 0\n",
        "  total_pb = 0\n",
        "\n",
        "  num_moves_required = 81-torch.count_nonzero(initial_board.argmax(dim=-1))\n",
        "\n",
        "  # breakpoint()\n",
        "  for t in range(num_moves_required.item()):\n",
        "    cat = torch.distributions.Categorical(logits=pf)\n",
        "    action = cat.sample()\n",
        "\n",
        "    total_pf += cat.log_prob(action)\n",
        "\n",
        "    n=9\n",
        "\n",
        "    x = action // (n ** 2)\n",
        "    y = (action % (n ** 2)) // n\n",
        "    z = (action % (n ** 2)) % n + 1\n",
        "    # breakpoint()\n",
        "    new_move = torch.zeros((9,9,10))\n",
        "    new_move[x, y, z] = 1\n",
        "    new_move[x, y, 0] = -1\n",
        "\n",
        "    # print(board.argmax(dim=-1),'\\n', new_move.argmax(dim=-1))\n",
        "    board = board + new_move\n",
        "\n",
        "    if torch.count_nonzero(torch.tensor(get_valid_moves(board.squeeze(0).argmax(dim=-1)))).item() == 0:\n",
        "      # breakpoint()\n",
        "      reward = torch.tensor(calculate_reward(board))\n",
        "\n",
        "    pf, pb = model(board, initial_board)\n",
        "\n",
        "    total_pb = torch.distributions.Categorical(logits=pb).log_prob(action)\n",
        "  # breakpoint()\n",
        "  loss = (model.logZ + total_pf - torch.log(reward).clip(-20) - total_pf).pow(2)\n",
        "  minibatch_loss += loss\n",
        "\n",
        "  generated_boards.append(board)\n",
        "\n",
        "  if episode % update_freq == 0:\n",
        "    losses.append(minibatch_loss.item())\n",
        "    if episode % 10 == 0:\n",
        "        pbar.update(10)\n",
        "        pbar.set_description(f\"Loss: {minibatch_loss.item():.4f}\")\n",
        "    minibatch_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    minibatch_loss = 0\n",
        "    logZs.append(model.logZ.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2c7b94e048744b5090260168d13ae7b3",
            "b5ea323ad2f64739897e78790925440a",
            "05125306a511436c8a071f234eb4849a",
            "570cae3f6d9649c784cfd68f43b6f716",
            "beca089a471140f9be2d9421f898b256",
            "4546c7a8190f4f66ab2b19a85ce63489",
            "91d2d2164f1149f88938d40296aa7c93",
            "a2d1d8fc6cfe4a65bbabc2724aa88f08",
            "76022c6604884767976801d9face479f",
            "435052a0872647158fb3afe91a713241",
            "ef57d11d72e049aaac262547c3e5680b"
          ]
        },
        "id": "HlmmAGY1lKWZ",
        "outputId": "377d5055-8f51-484c-b30b-26c23639977d"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c7b94e048744b5090260168d13ae7b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"./content/\")"
      ],
      "metadata": {
        "id": "04pg9Ews3hcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(0, 5000//update_freq), losses)"
      ],
      "metadata": {
        "id": "eDvSKoC9rk3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(0, 5000//update_freq), logz)"
      ],
      "metadata": {
        "id": "6yeLonagrpig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor([[[6, 1, 3, 7, 5, 9, 4, 2, 8],\n",
        "         [4, 5, 7, 3, 8, 2, 1, 9, 6],\n",
        "         [9, 8, 2, 0, 4, 6, 7, 3, 5],\n",
        "         [1, 2, 6, 4, 3, 7, 5, 8, 9],\n",
        "         [5, 3, 8, 6, 9, 1, 2, 7, 4],\n",
        "         [7, 9, 4, 5, 2, 8, 3, 6, 1],\n",
        "         [2, 6, 5, 9, 1, 3, 8, 4, 7],\n",
        "         [8, 7, 1, 2, 6, 4, 9, 5, 3],\n",
        "         [3, 4, 9, 8, 7, 5, 6, 1, 2]]])"
      ],
      "metadata": {
        "id": "0qt9V-eKJZLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# old stuff"
      ],
      "metadata": {
        "id": "SRbOu4OCJZub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from typing import bool\n",
        "\n",
        "def check_valid_sudoku(puzz: torch.TensorType) -> bool:\n",
        "  # check rows & columns\n",
        "  puzz = puzz.argmax(dim=-1)\n",
        "  for i in range(9):\n",
        "    row = puzz[i, :]\n",
        "\n",
        "    nonzero_row = row[row != 0]\n",
        "\n",
        "    if len(torch.unique(nonzero_row)) != len(nonzero_row):\n",
        "      return False\n",
        "\n",
        "    col = puzz[: , i]\n",
        "\n",
        "    nonzero_col = col[col != 0]\n",
        "\n",
        "    if len(torch.unique(nonzero_col)) != len(nonzero_col):\n",
        "      return False\n",
        "\n",
        "  # check subgrids\n",
        "  for i in range(0, 9, 3):\n",
        "    for j in range(0, 9, 3):\n",
        "      subgrid = puzz[i:i+3, j:j+3]\n",
        "\n",
        "      nonzero = subgrid[subgrid != 0].view(-1)\n",
        "\n",
        "      if len(torch.unique(nonzero)) != len(nonzero):\n",
        "        return False\n",
        "\n",
        "  return True"
      ],
      "metadata": {
        "id": "cQ8d4bcCFAeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_finished(puzz: torch.TensorType) -> bool:\n",
        "  if torch.count_nonzero(puzz.argmax(dim=-1)) != 81:\n",
        "    return False\n",
        "  else:\n",
        "    return True"
      ],
      "metadata": {
        "id": "wUkYIUwmL3JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_reward(puzz: torch.TensorType):\n",
        "  if not check_valid_sudoku(puzz) or not check_finished(puzz):\n",
        "    return 0\n",
        "\n",
        "  # sudoku finished successfully :party:\n",
        "  # elif len(torch.unique(torch.where(puzz.view(-1) > 0))) == 81:\n",
        "\n",
        "  elif torch.count_nonzero(puzz.argmax(dim=-1)).item() == 81:\n",
        "    return 3\n",
        "\n",
        "  else:\n",
        "    # previously 1, but that seems like an improper implementation, as non-terminal states should not have any reward.\n",
        "    return 0"
      ],
      "metadata": {
        "id": "GNolXwuXJaML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = next(iter(test_loader))\n",
        "#x.shape, y.shape\n",
        "\n",
        "#\n",
        "#calculate_reward(x.view(32, -1))\n",
        "#check_valid_sudoku(x[0].argmax(dim=-1))\n",
        "# check_finished(y[0])\n",
        "81-torch.count_nonzero(x[1].argmax(dim=-1)).item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL9IkWdmKIi1",
        "outputId": "8e41556d-3aff-4dec-9d59-6009c4282ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StateFlow(nn.Module):\n",
        "  def __init__(self, num_hidden=729*2):\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(810, num_hidden),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(num_hidden, 729)\n",
        "    ) # predict 810 states, mask out the ones we can't take (ie already filled or would conflict) -> sike we just let the model figure out the rest lmao\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    invalid_moves = torch.ones_like(x)\n",
        "    # only thing you can't move is to an empty state -- let this model figure out the rest\n",
        "    invalid_moves[:, :, :, 0] = 0\n",
        "    return self.mlp(x).exp() * invalid_moves"
      ],
      "metadata": {
        "id": "Y1wd1td_51x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_parents(x):\n",
        "  parent_states = []\n",
        "  parent_actions = []\n",
        "\n",
        "  for i in range(x):"
      ],
      "metadata": {
        "id": "WW1O8xL5Isbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONSTRUCTION ZONE - pls ping Alexander when you make changes here :)\n",
        "class StateFlow(nn.Module):\n",
        "  def __init__(self, num_hidden):\n",
        "    # consider a convolution here to expand this into channels grid by grid\n",
        "    # or potentially an attention layer, intialized with row by row\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(810, num_hidden),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(num_hidden, 729)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # not sure if we need to do onehot encodeing here or something similar in order to deal with gradient sizing\n",
        "    # onehot encoding is a go\n",
        "    # what if we do a 9 factor step at once? (for later)\n",
        "    # ignore filled lines (this happens later)\n",
        "    # allowing deletions lets you effectively introduce cycles by letting the model eliminate values.  is this a problem from a flow consistency standpoint?\n",
        "    # not allowing for now\n",
        "    mask = (x[:,:,0]==0).float()\n",
        "\n",
        "    return torch.cat([\n",
        "                      torch.zeros(9,9,1),\n",
        "                      torch.exp(self.mlp(x)).view(9,9,9)*mask\n",
        "                    ], dim=-1).view(-1)\n"
      ],
      "metadata": {
        "id": "-qd5imp8Kpg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# something something model forward.  this needs to handle batches, but as a preliminary overview\n",
        "\n",
        "dist = torch.distributions.Categorical(model(puzz))\n",
        "sample = dist.sample(dist.softmax(dim=-1))\n",
        "\n",
        "one_hot_enc = F.one_hot(9 if sample.item() % 9 == 0 else sample.item() % 9)\n",
        "x,y = (sample.item()%81 )//9, (sample.item()%81 )%9\n",
        "puzz[x,y] = one_hot_enc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "_Zxx1cNScpoY",
        "outputId": "35e77c90-61a1-408f-8bc7-a46bd6274e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b9b1a3ea67f3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# something something model forward.  this needs to handle batches, but as a preliminary overview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpuzz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[0;32m<ipython-input-27-b9b1a3ea67f3>\u001b[0m(3)\u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m      1 \u001b[0;31m\u001b[0;31m# something something model forward.  this needs to handle batches, but as a preliminary overview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      2 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m\u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpuzz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m      5 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "--KeyboardInterrupt--\n",
            "\n",
            "KeyboardInterrupt: Interrupted by user\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need to write sudoku candidate values functions to get entropy for this board (average entropy per cell, divided by the board overall, and maybe scaled further?)"
      ],
      "metadata": {
        "id": "e2yZZlWFNtOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING FUNCTION\n",
        "# good_sudoku_puzzle = torch.tensor([\n",
        "#     [5, 3, 0, 0, 7, 0, 0, 0, 0],\n",
        "#     [6, 0, 0, 1, 9, 5, 0, 0, 0],\n",
        "#     [0, 9, 8, 0, 0, 0, 0, 6, 0],\n",
        "#     [8, 0, 0, 0, 6, 0, 0, 0, 3],\n",
        "#     [4, 0, 0, 8, 0, 3, 0, 0, 1],\n",
        "#     [7, 0, 0, 0, 2, 0, 0, 0, 6],\n",
        "#     [0, 6, 0, 0, 0, 0, 2, 8, 0],\n",
        "#     [0, 0, 0, 4, 1, 9, 0, 0, 5],\n",
        "#     [0, 0, 0, 0, 8, 0, 0, 7, 9]\n",
        "# ])\n",
        "\n",
        "# bad_sudoku_puzzle_1 = torch.tensor([\n",
        "#     [5, 3, 0, 0, 7, 0, 0, 0, 0],\n",
        "#     [6, 3, 0, 1, 9, 5, 0, 0, 0],\n",
        "#     [0, 9, 8, 0, 0, 0, 0, 6, 0],\n",
        "#     [8, 0, 0, 0, 6, 0, 0, 0, 3],\n",
        "#     [4, 0, 0, 8, 0, 3, 0, 0, 1],\n",
        "#     [7, 0, 0, 0, 2, 0, 0, 0, 6],\n",
        "#     [0, 6, 0, 0, 0, 0, 2, 8, 0],\n",
        "#     [0, 0, 0, 4, 1, 9, 0, 0, 5],\n",
        "#     [0, 0, 0, 0, 8, 0, 0, 7, 9]\n",
        "# ])\n",
        "\n",
        "# bad_sudoku_puzzle_2 = torch.tensor([\n",
        "#     [5, 3, 3, 0, 7, 0, 0, 0, 0],\n",
        "#     [6, 0, 0, 1, 9, 5, 0, 0, 0],\n",
        "#     [0, 9, 8, 0, 0, 0, 0, 6, 0],\n",
        "#     [8, 0, 0, 0, 6, 0, 0, 0, 3],\n",
        "#     [4, 0, 0, 8, 0, 3, 0, 0, 1],\n",
        "#     [7, 0, 0, 0, 2, 0, 0, 0, 6],\n",
        "#     [0, 6, 0, 0, 0, 0, 2, 8, 0],\n",
        "#     [0, 0, 0, 4, 1, 9, 0, 0, 5],\n",
        "#     [0, 0, 0, 0, 8, 0, 0, 7, 9]\n",
        "# ])\n",
        "\n",
        "# bad_sudoku_puzzle_3 = torch.tensor([\n",
        "#     [5, 3, 0, 0, 7, 0, 0, 0, 0],\n",
        "#     [6, 0, 3, 1, 9, 5, 0, 0, 0],\n",
        "#     [0, 9, 8, 0, 0, 0, 0, 6, 0],\n",
        "#     [8, 0, 0, 0, 6, 0, 0, 0, 3],\n",
        "#     [4, 0, 0, 8, 0, 3, 0, 0, 1],\n",
        "#     [7, 0, 0, 0, 2, 0, 0, 0, 6],\n",
        "#     [0, 6, 0, 0, 0, 0, 2, 8, 0],\n",
        "#     [0, 0, 0, 4, 1, 9, 0, 0, 5],\n",
        "#     [0, 0, 0, 0, 8, 0, 0, 7, 9]\n",
        "# ])\n",
        "\n",
        "\n",
        "\n",
        "# assert check_valid_sudoku(good_sudoku_puzzle)\n",
        "# assert not check_valid_sudoku(bad_sudoku_puzzle_1)\n",
        "# assert not check_valid_sudoku(bad_sudoku_puzzle_2)\n",
        "# assert not check_valid_sudoku(bad_sudoku_puzzle_3)\n",
        "# print(\"check_sudoku test passed!\")"
      ],
      "metadata": {
        "id": "C-mp6aqoLx-g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}