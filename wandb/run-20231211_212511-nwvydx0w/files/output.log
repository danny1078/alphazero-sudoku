
  0%|          | 0/50 [00:00<?, ?it/s]
------ITER 1------
Average Score: 0.496737318505638
percentage of perfect games: 1.0



Training Net:  78%|███████▊  | 206/265 [00:04<00:00, 86.28it/s, Loss_pi=4.08e+00, Loss_v=4.16e+00]
Training Net: 100%|██████████| 265/265 [00:04<00:00, 53.16it/s, Loss_pi=4.06e+00, Loss_v=3.64e+00]
Training Net:  44%|████▍     | 117/265 [00:01<00:01, 83.29it/s, Loss_pi=3.94e+00, Loss_v=1.88e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 85.09it/s, Loss_pi=3.90e+00, Loss_v=1.82e+00]

Training Net:  75%|███████▍  | 198/265 [00:02<00:00, 85.31it/s, Loss_pi=3.80e+00, Loss_v=1.84e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 86.07it/s, Loss_pi=3.79e+00, Loss_v=1.82e+00]
Training Net:  41%|████      | 108/265 [00:01<00:01, 86.60it/s, Loss_pi=3.73e+00, Loss_v=1.88e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 86.60it/s, Loss_pi=3.72e+00, Loss_v=1.89e+00]

Training Net:  71%|███████▏  | 189/265 [00:02<00:00, 83.33it/s, Loss_pi=3.67e+00, Loss_v=1.86e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 84.37it/s, Loss_pi=3.67e+00, Loss_v=1.84e+00]

Training Net:  95%|█████████▌| 252/265 [00:03<00:00, 83.96it/s, Loss_pi=3.62e+00, Loss_v=1.84e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 81.97it/s, Loss_pi=3.62e+00, Loss_v=1.84e+00]
Training Net:  61%|██████    | 162/265 [00:01<00:01, 85.75it/s, Loss_pi=3.62e+00, Loss_v=1.88e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 82.27it/s, Loss_pi=3.62e+00, Loss_v=1.86e+00]

Training Net:  88%|████████▊ | 234/265 [00:02<00:00, 87.29it/s, Loss_pi=3.60e+00, Loss_v=1.84e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 86.04it/s, Loss_pi=3.60e+00, Loss_v=1.85e+00]
Training Net:  54%|█████▍    | 144/265 [00:01<00:01, 88.17it/s, Loss_pi=3.60e+00, Loss_v=1.86e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 86.07it/s, Loss_pi=3.59e+00, Loss_v=1.84e+00]

Training Net:  88%|████████▊ | 234/265 [00:02<00:00, 88.34it/s, Loss_pi=3.57e+00, Loss_v=1.85e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 87.72it/s, Loss_pi=3.57e+00, Loss_v=1.84e+00]
Training Net:  55%|█████▍    | 145/265 [00:01<00:01, 88.41it/s, Loss_pi=3.58e+00, Loss_v=1.80e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 87.53it/s, Loss_pi=3.58e+00, Loss_v=1.82e+00]

Training Net:  85%|████████▍ | 225/265 [00:02<00:00, 83.47it/s, Loss_pi=3.59e+00, Loss_v=1.83e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 84.82it/s, Loss_pi=3.58e+00, Loss_v=1.84e+00]
Training Net:  51%|█████     | 135/265 [00:01<00:01, 85.08it/s, Loss_pi=3.58e+00, Loss_v=1.85e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 85.67it/s, Loss_pi=3.58e+00, Loss_v=1.81e+00]

Training Net:  81%|████████  | 215/265 [00:02<00:00, 82.41it/s, Loss_pi=3.58e+00, Loss_v=1.85e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 84.78it/s, Loss_pi=3.58e+00, Loss_v=1.84e+00]

Training Net:  91%|█████████▏| 242/265 [00:02<00:00, 81.84it/s, Loss_pi=3.57e+00, Loss_v=1.81e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 83.16it/s, Loss_pi=3.57e+00, Loss_v=1.82e+00]
Training Net:  57%|█████▋    | 150/265 [00:01<00:01, 87.08it/s, Loss_pi=3.56e+00, Loss_v=1.85e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 81.85it/s, Loss_pi=3.57e+00, Loss_v=1.87e+00]

Training Net:  81%|████████  | 215/265 [00:02<00:00, 82.91it/s, Loss_pi=3.56e+00, Loss_v=1.89e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 83.47it/s, Loss_pi=3.57e+00, Loss_v=1.89e+00]
Training Net:  44%|████▍     | 117/265 [00:01<00:01, 85.16it/s, Loss_pi=3.56e+00, Loss_v=1.77e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 83.20it/s, Loss_pi=3.56e+00, Loss_v=1.77e+00]

Training Net:  73%|███████▎  | 193/265 [00:02<00:00, 86.88it/s, Loss_pi=3.58e+00, Loss_v=1.80e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 84.80it/s, Loss_pi=3.57e+00, Loss_v=1.80e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 85.50it/s, Loss_pi=3.57e+00, Loss_v=1.84e+00]
Training Net:   3%|▎         | 9/265 [00:00<00:02, 87.78it/s, Loss_pi=3.58e+00, Loss_v=2.01e+00]

Training Net:  71%|███████▏  | 189/265 [00:02<00:00, 88.53it/s, Loss_pi=3.55e+00, Loss_v=1.84e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 87.73it/s, Loss_pi=3.55e+00, Loss_v=1.80e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 86.23it/s, Loss_pi=3.57e+00, Loss_v=1.78e+00]
Training Net:   3%|▎         | 9/265 [00:00<00:03, 83.70it/s, Loss_pi=3.54e+00, Loss_v=1.94e+00]

Training Net:  71%|███████▏  | 189/265 [00:02<00:00, 88.59it/s, Loss_pi=3.57e+00, Loss_v=1.84e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 87.24it/s, Loss_pi=3.57e+00, Loss_v=1.86e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 87.09it/s, Loss_pi=3.57e+00, Loss_v=1.83e+00]
Training Net:   3%|▎         | 9/265 [00:00<00:02, 86.94it/s, Loss_pi=3.54e+00, Loss_v=1.81e+00]

Training Net:  68%|██████▊   | 180/265 [00:02<00:00, 86.29it/s, Loss_pi=3.56e+00, Loss_v=1.86e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 85.95it/s, Loss_pi=3.57e+00, Loss_v=1.84e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 86.65it/s, Loss_pi=3.58e+00, Loss_v=1.79e+00]
Training Net:   0%|          | 0/265 [00:00<?, ?it/s, Loss_pi=3.56e+00, Loss_v=2.12e+00]

Training Net:  68%|██████▊   | 181/265 [00:02<00:00, 87.40it/s, Loss_pi=3.56e+00, Loss_v=1.83e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 87.28it/s, Loss_pi=3.57e+00, Loss_v=1.84e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 86.61it/s, Loss_pi=3.58e+00, Loss_v=1.86e+00]
Training Net:   0%|          | 0/265 [00:00<?, ?it/s, Loss_pi=3.74e+00, Loss_v=1.83e+00]

Training Net:  65%|██████▍   | 171/265 [00:02<00:01, 86.37it/s, Loss_pi=3.57e+00, Loss_v=1.82e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 85.32it/s, Loss_pi=3.58e+00, Loss_v=1.83e+00]

Training Net:  75%|███████▍  | 198/265 [00:02<00:00, 87.14it/s, Loss_pi=3.57e+00, Loss_v=1.81e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 86.10it/s, Loss_pi=3.57e+00, Loss_v=1.83e+00]
Training Net:  44%|████▍     | 117/265 [00:01<00:01, 85.06it/s, Loss_pi=3.57e+00, Loss_v=1.72e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 83.39it/s, Loss_pi=3.57e+00, Loss_v=1.78e+00]

Training Net:  67%|██████▋   | 177/265 [00:02<00:01, 84.16it/s, Loss_pi=3.56e+00, Loss_v=1.82e+00]
Training Net: 100%|██████████| 265/265 [00:03<00:00, 82.06it/s, Loss_pi=3.57e+00, Loss_v=1.83e+00]
Training Net:  68%|██████▊   | 181/265 [00:02<00:00, 85.41it/s, Loss_pi=3.56e+00, Loss_v=1.79e+00]
  0%|          | 0/50 [03:09<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\Danny Han\Desktop\alphazero-sudoku\main.py", line 40, in <module>
    main()
  File "C:\Users\Danny Han\Desktop\alphazero-sudoku\main.py", line 36, in main
    t.learn()
  File "C:\Users\Danny Han\Desktop\alphazero-sudoku\Train.py", line 68, in learn
    self.nnet.train(self.data, wandb_logger=logger)
  File "C:\Users\Danny Han\Desktop\alphazero-sudoku\NNet.py", line 78, in train
    total_loss.backward()
  File "C:\Users\Danny Han\anaconda3\envs\ESE-5460_23\Lib\site-packages\torch\_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "C:\Users\Danny Han\anaconda3\envs\ESE-5460_23\Lib\site-packages\torch\autograd\__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt