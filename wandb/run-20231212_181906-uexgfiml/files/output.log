
  0%|          | 0/1 [00:00<?, ?it/s]
------ITER 1------
Average Score: 1.0000099999999998
percentage of perfect games: 1.0
mean and std of values:  1.0000099999999998 2.220446049250313e-16
(5, 4, 4)
[[1. 3. 2. 4.]
 [4. 2. 1. 3.]
 [2. 4. 3. 1.]
 [3. 1. 4. 0.]]
61
[[1. 3. 2. 4.]
 [4. 2. 1. 3.]
 [2. 4. 3. 1.]
 [3. 1. 4. 2.]]
EPOCH ::: 1
Validation - Mean of max policy element: 0.0158, Std Dev: 0.0000
Training Net: 100%|██████████| 12/12 [00:00<00:00, 14.37it/s, Loss_pi=4.16, Loss_v=1]
Training Net:   0%|          | 0/12 [00:00<?, ?it/s, Loss_pi=4.16, Loss_v=1]
Validation - Mean of max policy element: 0.0160, Std Dev: 0.0000
EPOCH ::: 3
Validation - Mean of max policy element: 0.0162, Std Dev: 0.0000
EPOCH ::: 4
Validation - Mean of max policy element: 0.0164, Std Dev: 0.0000
EPOCH ::: 5
Validation - Mean of max policy element: 0.0166, Std Dev: 0.0000
EPOCH ::: 6
Validation - Mean of max policy element: 0.0168, Std Dev: 0.0000
EPOCH ::: 7
Validation - Mean of max policy element: 0.0170, Std Dev: 0.0000
EPOCH ::: 8
Validation - Mean of max policy element: 0.0172, Std Dev: 0.0000
EPOCH ::: 9
Validation - Mean of max policy element: 0.0173, Std Dev: 0.0000
EPOCH ::: 10
Training Net: 100%|██████████| 12/12 [00:00<00:00, 342.40it/s, Loss_pi=4.15, Loss_v=1]
Training Net: 100%|██████████| 12/12 [00:00<00:00, 348.64it/s, Loss_pi=4.15, Loss_v=1]
Training Net: 100%|██████████| 12/12 [00:00<00:00, 393.31it/s, Loss_pi=4.15, Loss_v=1]
Training Net: 100%|██████████| 12/12 [00:00<00:00, 323.72it/s, Loss_pi=4.15, Loss_v=1]
Training Net: 100%|██████████| 12/12 [00:00<00:00, 308.90it/s, Loss_pi=4.15, Loss_v=1]
Training Net: 100%|██████████| 12/12 [00:00<00:00, 351.30it/s, Loss_pi=4.14, Loss_v=1]
Training Net: 100%|██████████| 12/12 [00:00<00:00, 334.19it/s, Loss_pi=4.14, Loss_v=1]
Training Net: 100%|██████████| 12/12 [00:00<00:00, 309.08it/s, Loss_pi=4.14, Loss_v=1]
Training Net: 100%|██████████| 12/12 [00:00<00:00, 332.32it/s, Loss_pi=4.14, Loss_v=1]
100%|██████████| 1/1 [00:27<00:00, 27.37s/it]